---
output:
  pdf_document:
    keep_tex: yes
    fig_caption: yes
    number_sections: yes
geometry: margin=2.54cm
title: "How bad is the current CO River drought?"
subtitle: "https://github.com/jbc70/Water_Data_Analytics_FinalProject"
author: "Jack Carpenter"
fontsize: 12pt
mainfont: Times New Roman
editor_options: 
  chunk_output_type: console
---
\newpage
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#setwd
getwd()

#load packages
library(tidyverse) 
library(dataRetrieval)
library(cowplot)
library(lubridate)
library(lfstat)
library(sf)
library(maps)
library(gganimate)
library(tseries)

#set ggplot theme
theme_set(theme_classic()+
            theme(axis.text = element_text(color = "black", size = 10)))
```

# Rationale and Research Questions

The Colorado River Basin is experiencing a 20+ year drought that is repeatedly referred to as a 'megadrought' in the news media. The goal of this project is to vizualize the differences in discharge of the Colorado River and some of its major tributaries over the last 20 years compared to earlier, wetter, more 'normal' time frames. In a snowpack-fueled system like the Colorado, timing is also important because runoff provides much of the water entering the system and earlier runoff can make droughts more severe later in the year.

Due to the size and managed nature of the system, different regions in the basin may also be experiencing the drought differently. Another aspect of this project is to look at the different sites to see how flows are different in different parts of the basin. 

Questions:

> 1. How do discharge and baseflow change through the current drought. Is there noticeable change? 

> 2. How do different parts of the basin look during the drought? Are there significant differences by location? 

Workflow/Process:
> 1. Identify where are there gages with reliable, long-enough datasets to make this comparison.
> 2. Separate data at 1999 - the current drought started in the 1999-2000 water year.
> 3. Examine and compare discharge patterns and volumes across the basin and between time periods.

\newpage

# Dataset Information
``` {r Read in the Data, include = FALSE, echo = FALSE}
#load the data - daily values is dv
#reading all the sites in at once, then going to separate them when wrangling
allsites.raw <- readNWISdv(siteNumbers = c("09209400",
                                           "09058000",
                                           "09234500",
                                           "09251000",
                                           "09095500",
                                           "09152500",
                                           "09315000",
                                           "09163500",
                                           "09180000",
                                           "09739500",
                                           "09380000",
                                           "09421500",
                                           "09520500",
                                           "09429490"),
                           parameterCd = "00060", #discharge in cfs
                           startDate = "", #no set start date
                           endDate = "2021-09-30") #through the latest water year

#rename columns to make sense
names(allsites.raw)[4:5] <- c("Discharge_cfs", "Approval_Code")

#check date is actually a date
class(allsites.raw$Date)

#write csv with data
#write_csv(allsites.raw, file = "./Data/Raw/allsites_raw.csv")
#commented out to allow knitting
```
Data was pulled from the United States Geologic Survey's (USGS) National Water Information System (NWIS) using the dataRetrieval package. Significant tributaries sampled alongside the Colorado include the Gunnison, Yampa, San Juan, Dolores, Green, Gila, and Virgin Rivers. Other relatively large tributaries exist, including the Little Colorado, Roaring Fork, and White rivers, but due to data constraints and an interest in keeping the size of the project under control only the largest tributaries with relatively consistent data were sampled. The gage sites selected were selected both for location convenience and the length of time the gage has been active. Most of these gages have been active since the 1950s, with several active as far back as the early 1900s. Since the data comes from the USGS, it has been subjected to rigorous cleaning and quality approval processes so it is considered to be accurate and trustworthy. 

Table 1: USGS Gages sampled. 

Gage Number | Location
------------|---------------
09209400    |Green River above Fontenelle Reservoir, WY
09058000    |CO River near Kremmling, CO
09234500    |Green River below Flaming Gorge Dam
09251000    |Yampa River upstream of junction w/ Green
09095500    |CO River upstream of Grand Junction, CO
09152500    |Gunnison River near Grand Junction, CO
09315000    |Green River at Green River, UT
09163500    |CO River downstream of Grand Junction, CO
09180000    |Dolores River just upstream of junction w/ Colorado
09379500    |San Juan River upstream of Lake Powell (intersection w/ the CO)
09380000    |CO River at Lee's Ferry, AZ
09421500    |CO River below Hoover Dam
09520500    |Gila River above Yuma, AZ
09429490    |CO River above Imperial Dam

\newpage

# Exploratory Analysis
First thing's first: take a look at what data we have to work with. 
```{r initial visualization, echo=FALSE}
rawdata.plot <- ggplot(allsites.raw, aes(x = Date, y = Discharge_cfs, color = site_no)) +
  geom_point(alpha = 0.5, size = 0.3) +
  scale_color_viridis_d() +
  scale_y_log10() +
  labs(x = "Date", y = "Discharge (cfs)", color = "Site")
rawdata.plot
```
After initial visualization, the Gila river data has been thrown out because there are so many zeroes. This is potentially due to the fact that this gage site is very near Yuma, Arizona where there is significant agriculture. Diversions in this area could be artificially lowering the level of the river there because it is such a heavily agricultural area.

The next step in exploratory analysis is to wrangle the data into something useful. In this case, that means separating the data by gage. This could have been done by reading each gage in separately, but in this case it was done by filtering the large set already read in. 

```{r Wrangle like a Data Cowboy, include = FALSE}
#initial cleanup
allsites.processed <- allsites.raw %>%
  filter(site_no != "09520500") %>% #remove the Gila data
  mutate(Baseflow_lfstat = baseflow(Discharge_cfs),#compute baseflow
         Stormflow_lfstat = Discharge_cfs - Baseflow_lfstat, #compute stormflow, but likely won't use it
         Water_Year = water_year(Date), #add water year column - between-year comparison
         DOY = yday(Date),
         Month = month(Date)) #add DOY - in-year comparisons

#plotting processed data to see if it's any use
allprocessed.plot <- ggplot(allsites.processed) +
  geom_point(aes(x = Water_Year, y = Baseflow_lfstat, color = site_no),
             alpha = 0.3, size = 0.3) +
  scale_y_log10() +
  scale_color_viridis_d() +
  labs(x = "Water Year", y = "Baseflow (cfs)", color = "Gage #")
allprocessed.plot
#cool to see, but not particularly helpful
#still going to write the csv
#write_csv(allsites.processed, file = "./Data/Processed/allsites_processed.csv")
#again, commented out to knit

#let's see if we can isolate just the drought years
current.drought <- allsites.processed %>%
  filter(Date > "1999-09-30")
#plot to see if its worth keeping
ggplot(current.drought, aes(x = Date, y = Discharge_cfs, color = site_no)) +
  geom_line() +
  scale_y_log10()+
  labs(x = "Date", y = "Discharge(cfs)", color = "Gage No.")
ggplot(current.drought, aes(x = DOY, y = Discharge_cfs, color = site_no)) +
  geom_point(alpha = 0.5, size = 0.3) +
  scale_y_log10() +
  scale_color_viridis_d() +
  labs(x = "Day of Year", y = "Discharge (cfs)", color = "Gage No.")
#cool data, going to keep it, also allows me to ask a different question
#write.csv(current.drought, file = "./Data/Processed/current_drought.csv")

#now to select earlier data
#choosing 1967 b/c Glen Canyon Dam was completed in 1963
earlier.years <- allsites.processed %>%
  filter(Date > "1964-09-30" & Date < "1999-10-01")

ggplot(earlier.years, aes(x = DOY, y = Discharge_cfs, color = site_no))+
  geom_point(alpha = 0.5, size = 0.3) +
  scale_y_log10() +
  scale_color_viridis_d() +
  labs(x = "Day of Year", y = "Discharge (cfs)", color = "Gage No.")
#write.csv(earlier.years, file = "./Data/Processed/1967to1999.csv")

#realized I gotta make a summary to get useful data
allsites.summary <- allsites.processed %>%
  group_by(site_no, Water_Year) %>%
  summarise(Discharge.acft.yr = sum(Discharge_cfs)*723.968, #convert cfs to ac-ft/yr
            Baseflow.acft.yr = sum(Baseflow_lfstat)*723.968,
            Stormflow.acft.yr = sum(Stormflow_lfstat)*723.968,
            prop.baseflow = Baseflow.acft.yr/Discharge.acft.yr,
            prop.stormflow = Stormflow.acft.yr/Discharge.acft.yr)

ggplot(allsites.summary, aes(x = Water_Year)) +
  geom_point(aes(y = Discharge.acft.yr), alpha = 0.8, size = 0.5, color = "grey") +
  geom_point(aes(y = Baseflow.acft.yr), alpha = 0.8, size = 0.5, color = "black") +
  scale_color_viridis_d() +
  labs(x = "Water Year", y = "Flow (ac-ft/yr)")

# now to summarize each time period of interest
current.drought.summary <- current.drought %>%
  group_by(site_no,Water_Year)
```

``` {Individual Sites, include = FALSE}
#select by sites
Green.at.Fontenelle <- allsites.processed %>%
  filter(site_no == "09209400")
CO.at.Kremmling <- allsites.processed %>%
  filter(site_no == "09058000")
Green.below.FlamingGorge <- allsites.processed %>%
  filter(site_no == "09234500")
Yampa.above.Green <- allsites.processed %>%
  filter(site_no == "09251000")
CO.above.GrandJunction <- allsites.processed %>%
  filter(site_no == "09095500")
Gunnison.near.GrandJunction <- allsites.processed %>%
  filter(site_no == "09152500")
Green.at.GreenRiver <- allsites.processed %>%
  filter(site_no == "09315000")
CO.below.GrandJunction <- allsites.processed %>%
  filter(site_no == "09163500")
Dolores.river <- allsites.processed %>%
  filter(site_no == "09180000")
SanJuan.River <- allsites.processed %>%
  filter(site_no == "09379500")
Lee.Ferry <- allsites.processed %>%
  filter(site_no == "09380000")
CO.at.Hoover <- allsites.processed %>%
  filter(site_no == "09421500")
CO.at.Imperial <- allsites.processed %>%
  filter(site_no == "09429490")

#now to plot all of these individually

```
\newpage

# Analysis
Time series to see trend? For overall and/or by site between two time periods

## Question 1

\newpage

# Summary and Conclusions

\newpage

#References


